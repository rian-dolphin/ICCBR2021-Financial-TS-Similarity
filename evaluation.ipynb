{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Code\n",
    "\n",
    "This code relates to the paper \"Measuring Financial Time Series Similarity With a View to Identifying Profitable Stock Market Opportunities\" which was published in the proceedings of the International Conference on Case Based Reasoning (ICCBR) 2021\n",
    "\n",
    "For queries please email rian.dolphin@ucdconnect.ie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Imports\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "#from scipy.special import softmax\n",
    "import time\n",
    "\n",
    "import datetime as dt\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "#-- Uncomment these for white Theme\n",
    "my_template = 'plotly_white'\n",
    "background_color = 'rgba(255,255,255,1)'\n",
    "\n",
    "#-- Dark Theme\n",
    "#my_template = 'plotly_dark'\n",
    "#background_color = 'rgba(0,0,0,1)'\n",
    "\n",
    "#-- Dark Transparent background\n",
    "#my_template = 'plotly_dark'\n",
    "#background_color = 'rgba(0,0,0,0)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Rolling Dfs Loaded ===\n"
     ]
    }
   ],
   "source": [
    "#-- Load in from saved files\n",
    "import os, os.path\n",
    "\n",
    "def sort_date(df):\n",
    "    df.start_date = pd.to_datetime(df.start_date, unit='ms')\n",
    "    df.end_date = pd.to_datetime(df.end_date, unit='ms')\n",
    "    df.sort_values(by=['start_date'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# simple version for working with CWD\n",
    "#print(len([name for name in os.listdir('All_Windows/')]))\n",
    "\n",
    "rolling_dfs = []\n",
    "path = 'Windows_2021_Short/'\n",
    "files = [name for name in os.listdir(path)]\n",
    "files = [file for file in files if file.startswith('window')]\n",
    "count=1\n",
    "for file_name in files:\n",
    "    temp_df = pd.read_json(path+'window_'+str(count)+'.json')\n",
    "    temp_df = sort_date(temp_df)\n",
    "    rolling_dfs.append(temp_df)\n",
    "    #df.to_json(file_name)\n",
    "    count+=1\n",
    "    if count==250:\n",
    "        break\n",
    "print('=== Rolling Dfs Loaded ===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_metric(rolling_dfs, metric, reverse=True):\n",
    "    \"\"\"\n",
    "    Function which will order the cases by the given similarity metric\n",
    "    \"\"\"\n",
    "    for df_i in tqdm(range(len(rolling_dfs))):\n",
    "        df = rolling_dfs[df_i].copy()\n",
    "        df = df.astype('object')\n",
    "        for i in range(len(df)):\n",
    "            temp = df.iloc[i][7:]\n",
    "            df.loc[df.index[i], metric], df.loc[df.index[i], 'sim_idx_val'], df.loc[df.index[i], 'sim_next_month'], df.loc[df.index[i], 'sim_next_year'], df.loc[df.index[i], 'correlations'], df.loc[df.index[i], 'cumprod_diffs'], df.loc[df.index[i], 'shape_measure'], df.loc[df.index[i], 'equal_weight_similarity'], df.loc[df.index[i], 'quantdare']=zip(*sorted(zip(temp[metric], temp['sim_idx_val'], temp['sim_next_month'], temp['sim_next_year'],temp['correlations'], temp['cumprod_diffs'], temp['shape_measure'], temp['equal_weight_similarity'], temp['quantdare']), reverse=reverse))\n",
    "        rolling_dfs[df_i] = df\n",
    "    return copy.deepcopy(rolling_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the results seen in Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(rolling_dfs,k, aggregation=False, seed=False):\n",
    "    if seed!=False:\n",
    "        np.random.seed(seed)\n",
    "        tickers = list(rolling_dfs[0].ticker.value_counts().index)\n",
    "        tickers = np.random.choice(tickers, int(len(tickers)*0.2), replace=False)\n",
    "        \n",
    "        rolling_dfs = [df[~df.ticker.isin(tickers)] for df in rolling_dfs]\n",
    "        \n",
    "        x_top = np.array([abs((np.array([np.array(xi)[:k] for xi in df[df.start_date==df.start_date.iloc[0]].sim_next_month.values])).flatten()) for df in rolling_dfs]).flatten()\n",
    "        \n",
    "        \n",
    "    elif aggregation:\n",
    "        #x_top = np.array([abs((np.array([np.array(xi)[:k] for xi in df[df.start_date==df.start_date.iloc[0]].sim_next_month.values]).mean()-df[df.start_date==df.start_date.iloc[0]].next_month.values.reshape(-1,1)).flatten()) for df in rolling_dfs]).flatten()\n",
    "        x_top = np.array([(np.array([np.random.choice(np.array(xi),k,replace=False) for xi in df[df.start_date==df.start_date.iloc[0]].sim_next_month.values]).mean()).flatten() for df in rolling_dfs]).flatten()\n",
    "        #x_top = np.array([(np.array([np.array(xi)[:k] for xi in df[df.start_date==df.start_date.iloc[0]].sim_next_month.values]).mean()).flatten() for df in rolling_dfs]).flatten()\n",
    "    else:\n",
    "        #-- Use line below for errors (Table 1)\n",
    "        x_top = np.array([abs((np.array([np.array(xi)[:k] for xi in df[df.start_date==df.start_date.iloc[0]].sim_next_month.values])-df[df.start_date==df.start_date.iloc[0]].next_month.values.reshape(-1,1)).flatten()) for df in rolling_dfs]).flatten()\n",
    "        #-- Use line below for random!\n",
    "        #x_top = np.array([abs((np.array([np.random.choice(np.array(xi),k,replace=False) for xi in df[df.start_date==df.start_date.iloc[0]].sim_next_month.values])-df[df.start_date==df.start_date.iloc[0]].next_month.values.reshape(-1,1)).flatten()) for df in rolling_dfs]).flatten()\n",
    "        #-- Use line below for trading sim? NO SINCE ABS\n",
    "        #x_top = np.array([abs((np.array([np.array(xi)[:k] for xi in df[df.start_date==df.start_date.iloc[0]].sim_next_month.values])).flatten()) for df in rolling_dfs]).flatten()\n",
    "        #-- line below for Random Trading sim\n",
    "        #x_top = np.array([abs((np.array([np.random.choice(np.array(xi),k,replace=False) for xi in df[df.start_date==df.start_date.iloc[0]].sim_next_month.values])).flatten()) for df in rolling_dfs]).flatten()\n",
    "    #x_bottom = np.array([abs((np.array([np.array(xi)[-k:] for xi in df[df.start_date==df.start_date.iloc[0]].sim_next_month.values])-df[df.start_date==df.start_date.iloc[0]].next_month.values.reshape(-1,1)).flatten()) for df in rolling_dfs]).flatten()\n",
    "    #x_rand = np.array([abs((np.array([np.array(xi)[[np.random.randint(0,len(xi)) for i in range(k)]] for xi in df[df.start_date==df.start_date.iloc[0]].sim_next_month.values])-df[df.start_date==df.start_date.iloc[0]].next_month.values.reshape(-1,1)).flatten()) for df in rolling_dfs]).flatten()\n",
    "    #print(x_top.shape)\n",
    "    return x_top.mean(), x_top.std(), x_top\n",
    "\n",
    "\n",
    "def add_to_error_dict(rolling_dfs, metric, aggregation=False, seed=False):\n",
    "    temp_dict = {}\n",
    "    for k in [1,2,5,10,25,50]:\n",
    "        temp_dict[k] = get_error(rolling_dfs,k, aggregation=aggregation, seed=seed)\n",
    "    error_dict[metric] = temp_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDING ProposedAdjusted\n",
      "====================\n",
      "alpha = 0.5\n",
      "beta = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [05:44<00:00,  2.00s/it]\n"
     ]
    }
   ],
   "source": [
    "#-- Define empty dictionary to store errors\n",
    "error_dict = {}\n",
    "#-- Set aggregation parameter\n",
    "agg = False\n",
    "\n",
    "#-- Add the proposed metric\n",
    "print(\"ADDING ProposedAdjusted\")\n",
    "for alpha in [0.5]:\n",
    "    print('='*20)\n",
    "    beta=1-alpha\n",
    "    print(f'alpha = {alpha}')\n",
    "    print(f'beta = {beta}')\n",
    "    for df in rolling_dfs:\n",
    "        temp_weighted_similarity = []\n",
    "        for i in range(len(df)):\n",
    "            temp_weighted_similarity.append((1/(1+np.array(df.iloc[i].cumprod_diffs))*alpha + (beta * np.array(df.iloc[i].quantdare))))\n",
    "\n",
    "        df['weighted_similarity'] = temp_weighted_similarity\n",
    "\n",
    "    weighted_rolling = sort_by_metric(rolling_dfs, 'weighted_similarity')\n",
    "    #top_vs_bottom_histogram(weighted_rolling,k=20, plots=True)\n",
    "add_to_error_dict(weighted_rolling, 'weighted_similarity', aggregation=agg, seed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDING ProposedPearson\n",
      "====================\n",
      "alpha = 0.5\n",
      "beta = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [01:35<00:00,  1.80it/s]\n",
      "  0%|          | 0/172 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDING Shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [01:26<00:00,  1.98it/s]\n",
      "  0%|          | 0/172 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDING PearsonOnly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [01:22<00:00,  2.10it/s]\n",
      "  0%|          | 0/172 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDING CumulativeOnly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [01:22<00:00,  2.09it/s]\n",
      "  0%|          | 0/172 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDING AdjustedOnly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [01:22<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QD Done\n"
     ]
    }
   ],
   "source": [
    "#-- Add the remaining baselines\n",
    "print(\"ADDING ProposedPearson\")\n",
    "for alpha in [0.5]:\n",
    "    print('='*20)\n",
    "    beta=1-alpha\n",
    "    print(f'alpha = {alpha}')\n",
    "    print(f'beta = {beta}')\n",
    "    for df in rolling_dfs:\n",
    "        temp_weighted_similarity = []\n",
    "        for i in range(len(df)):\n",
    "            temp_weighted_similarity.append((1/(1+np.array(df.iloc[i].cumprod_diffs))*alpha + (beta * np.array(df.iloc[i].correlations))))\n",
    "\n",
    "        df['equal_weight_similarity'] = temp_weighted_similarity\n",
    "\n",
    "    equal_rolling = sort_by_metric(rolling_dfs, 'equal_weight_similarity')\n",
    "add_to_error_dict(equal_rolling, 'equal_weight_similarity', aggregation=agg, seed=False)\n",
    "del equal_rolling\n",
    "\n",
    "print(\"ADDING Shape\")\n",
    "shape_rolling = sort_by_metric(rolling_dfs, 'shape_measure')\n",
    "add_to_error_dict(shape_rolling, 'shape_measure', aggregation=agg, seed=False)\n",
    "del shape_rolling\n",
    "\n",
    "print(\"ADDING PearsonOnly\")\n",
    "correlation_rolling = sort_by_metric(rolling_dfs, 'correlations')\n",
    "add_to_error_dict(correlation_rolling, 'correlations', aggregation=agg, seed=False)\n",
    "del correlation_rolling\n",
    "\n",
    "print(\"ADDING CumulativeOnly\")\n",
    "cumprod_rolling = sort_by_metric(rolling_dfs, 'cumprod_diffs', reverse=False)\n",
    "add_to_error_dict(cumprod_rolling, 'cumprod_diffs', aggregation=agg, seed=False)\n",
    "del cumprod_rolling\n",
    "\n",
    "print(\"ADDING AdjustedOnly\")\n",
    "qd_rolling = sort_by_metric(rolling_dfs, 'quantdare')\n",
    "add_to_error_dict(qd_rolling, 'quantdare', aggregation=agg, seed=False)\n",
    "del qd_rolling\n",
    "print('QD Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-0150f9dfa66b>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  df = pd.DataFrame(np.array(list(error_dict['weighted_similarity'].values()))[:,0], index=[1,2,5,10,25,50], columns=['weighted_similarity'])\n",
      "<ipython-input-7-0150f9dfa66b>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  df[metric]=np.array(list(error_dict[metric].values()))[:,0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weighted_similarity</th>\n",
       "      <td>0.0887294</td>\n",
       "      <td>0.088549</td>\n",
       "      <td>0.0882301</td>\n",
       "      <td>0.0882748</td>\n",
       "      <td>0.0882213</td>\n",
       "      <td>0.0882663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal_weight_similarity</th>\n",
       "      <td>0.0893349</td>\n",
       "      <td>0.0890898</td>\n",
       "      <td>0.0884871</td>\n",
       "      <td>0.0883485</td>\n",
       "      <td>0.0882824</td>\n",
       "      <td>0.0884208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shape_measure</th>\n",
       "      <td>0.0887873</td>\n",
       "      <td>0.0887696</td>\n",
       "      <td>0.0888952</td>\n",
       "      <td>0.0888617</td>\n",
       "      <td>0.0890942</td>\n",
       "      <td>0.0892939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correlations</th>\n",
       "      <td>0.0909763</td>\n",
       "      <td>0.091096</td>\n",
       "      <td>0.0909417</td>\n",
       "      <td>0.0909025</td>\n",
       "      <td>0.0908742</td>\n",
       "      <td>0.090789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cumprod_diffs</th>\n",
       "      <td>0.0910655</td>\n",
       "      <td>0.0911922</td>\n",
       "      <td>0.0907582</td>\n",
       "      <td>0.0906796</td>\n",
       "      <td>0.0904136</td>\n",
       "      <td>0.090249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantdare</th>\n",
       "      <td>0.0910664</td>\n",
       "      <td>0.0909644</td>\n",
       "      <td>0.0907465</td>\n",
       "      <td>0.090755</td>\n",
       "      <td>0.0906666</td>\n",
       "      <td>0.0905435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                1          2          5          10  \\\n",
       "weighted_similarity      0.0887294   0.088549  0.0882301  0.0882748   \n",
       "equal_weight_similarity  0.0893349  0.0890898  0.0884871  0.0883485   \n",
       "shape_measure            0.0887873  0.0887696  0.0888952  0.0888617   \n",
       "correlations             0.0909763   0.091096  0.0909417  0.0909025   \n",
       "cumprod_diffs            0.0910655  0.0911922  0.0907582  0.0906796   \n",
       "quantdare                0.0910664  0.0909644  0.0907465   0.090755   \n",
       "\n",
       "                                25         50  \n",
       "weighted_similarity      0.0882213  0.0882663  \n",
       "equal_weight_similarity  0.0882824  0.0884208  \n",
       "shape_measure            0.0890942  0.0892939  \n",
       "correlations             0.0908742   0.090789  \n",
       "cumprod_diffs            0.0904136   0.090249  \n",
       "quantdare                0.0906666  0.0905435  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-- Display table 1\n",
    "df = pd.DataFrame(np.array(list(error_dict['weighted_similarity'].values()))[:,0], index=[1,2,5,10,25,50], columns=['weighted_similarity'])\n",
    "for metric in list(error_dict.keys())[1:]:\n",
    "    #print('='*20)\n",
    "    #print(metric)\n",
    "    df[metric]=np.array(list(error_dict[metric].values()))[:,0]\n",
    "display(df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proposed_10</th>\n",
       "      <th>pearson_cumprod_10</th>\n",
       "      <th>shape_10</th>\n",
       "      <th>pearson_10</th>\n",
       "      <th>cumprod_diffs_10</th>\n",
       "      <th>adjusted_corr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031954</td>\n",
       "      <td>0.095433</td>\n",
       "      <td>0.067251</td>\n",
       "      <td>0.057734</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>0.057734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.031954</td>\n",
       "      <td>0.071173</td>\n",
       "      <td>0.095433</td>\n",
       "      <td>0.060591</td>\n",
       "      <td>0.294980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.042043</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.230242</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.019239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030988</td>\n",
       "      <td>0.057734</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.041380</td>\n",
       "      <td>0.035972</td>\n",
       "      <td>0.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035923</td>\n",
       "      <td>0.042043</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.056056</td>\n",
       "      <td>0.089966</td>\n",
       "      <td>0.031954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proposed_10  pearson_cumprod_10  shape_10  pearson_10  cumprod_diffs_10  \\\n",
       "0     0.031954            0.095433  0.067251    0.057734          0.020649   \n",
       "1     0.056500            0.031954  0.071173    0.095433          0.060591   \n",
       "2     0.042043            0.056500  0.230242    0.021645          0.002037   \n",
       "3     0.030988            0.057734  0.000214    0.041380          0.035972   \n",
       "4     0.035923            0.042043  0.056500    0.056056          0.089966   \n",
       "\n",
       "   adjusted_corr_10  \n",
       "0          0.057734  \n",
       "1          0.294980  \n",
       "2          0.019239  \n",
       "3          0.056500  \n",
       "4          0.031954  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#-- Create a DF with all the underlying values which make up the aggregate errors table\n",
    "#- This will allow us to perform a Tukey HSD test\n",
    "raw_dict = {}\n",
    "for metric in error_dict.keys():\n",
    "    for k in [10]:\n",
    "        key = metric+'_'+str(k)\n",
    "        raw_dict[key] = error_dict[metric][k][2]\n",
    "temp_df = pd.DataFrame(raw_dict)\n",
    "\n",
    "temp_df.rename(columns={\"weighted_similarity_\"+str(k): \"proposed_\"+str(k),\n",
    "                   \"equal_weight_similarity_\"+str(k): \"pearson_cumprod_\"+str(k),\n",
    "                  \"shape_measure_\"+str(k): \"shape_\"+str(k),\n",
    "                  \"correlations_\"+str(k): \"pearson_\"+str(k),\n",
    "                  \"cumprod_diffs_\"+str(k): \"cumprod_diffs_\"+str(k),\n",
    "                  \"quantdare_\"+str(k): \"adjusted_corr_\"+str(k)},\n",
    "              inplace=True)\n",
    "\n",
    "#-- Save to csv and reload\n",
    "#- Without this step the Tukey test gives an error\n",
    "temp_df.to_csv('error_df_10.csv')\n",
    "temp_df = pd.read_csv('error_df_10.csv', index_col=0)\n",
    "\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group1</th>\n",
       "      <th>group2</th>\n",
       "      <th>meandiff</th>\n",
       "      <th>p-adj</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>reject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adjusted_corr_10</td>\n",
       "      <td>proposed_10</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cumprod_diffs_10</td>\n",
       "      <td>proposed_10</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pearson_10</td>\n",
       "      <td>proposed_10</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pearson_cumprod_10</td>\n",
       "      <td>proposed_10</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>proposed_10</td>\n",
       "      <td>shape_10</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                group1       group2  meandiff   p-adj   lower   upper  reject\n",
       "3     adjusted_corr_10  proposed_10   -0.0025  0.0010 -0.0031 -0.0018    True\n",
       "7     cumprod_diffs_10  proposed_10   -0.0024  0.0010 -0.0031 -0.0018    True\n",
       "10          pearson_10  proposed_10   -0.0026  0.0010 -0.0033 -0.0020    True\n",
       "12  pearson_cumprod_10  proposed_10   -0.0001  0.9000 -0.0007  0.0006   False\n",
       "14         proposed_10     shape_10    0.0006  0.0993 -0.0001  0.0012   False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- Perform a Tukey HSD Test\n",
    "#- Note that you need to do the save to CSV and reload in step for this to work\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "for column in temp_df.columns:\n",
    "    y_vals.append(temp_df[column].values)\n",
    "    x_vals.append([column for _ in range(len(temp_df[column].values))])\n",
    "\n",
    "x_vals=np.array(x_vals).flatten()\n",
    "y_vals=np.array(y_vals).flatten()\n",
    "\n",
    "# DataFrame.\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.multicomp as multi\n",
    "mcDate = multi.MultiComparison(y_vals,x_vals)\n",
    "Results = mcDate.tukeyhsd()\n",
    "#print(Results)\n",
    "\n",
    "temp_df = pd.DataFrame(data=Results._results_table.data[1:], columns=Results._results_table.data[0])\n",
    "temp_df[(temp_df.group1.str.contains('proposed')) | (temp_df.group2.str.contains('proposed'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Evaluation - Trading Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_returns(rolling_dfs,k, aggregation=False, seed=False):\n",
    "    if seed!=False:\n",
    "        np.random.seed(seed)\n",
    "        tickers = list(rolling_dfs[0].ticker.value_counts().index)\n",
    "        tickers = np.random.choice(tickers, int(len(tickers)*0.2), replace=False)\n",
    "        \n",
    "        rolling_dfs = [df[~df.ticker.isin(tickers)] for df in rolling_dfs]\n",
    "        \n",
    "        x_top = np.array([abs((np.array([np.array(xi)[:k].mean() for xi in df[df.start_date==df.start_date.iloc[0]].sim_next_month.values]))) for df in rolling_dfs])\n",
    "        \n",
    "    return x_top\n",
    "\n",
    "\n",
    "n_years = 172/12\n",
    "def get_cumulative_performance(rolling_dfs, k, n, subsample=True):\n",
    "    #-- Get returns of top-k most similar for the 80% of assests for each RW\n",
    "    \n",
    "    if subsample:\n",
    "        performance_list = []\n",
    "        for _ in tqdm(range(100)):\n",
    "            #-- Get the next month returns of top-k most similar cases\n",
    "            tickers = list(rolling_dfs[0].ticker.value_counts().index)\n",
    "            tickers = np.random.choice(tickers, int(len(tickers)*0.2), replace=False)\n",
    "\n",
    "            temp_rolling_dfs = [df[~df.ticker.isin(tickers)] for df in rolling_dfs]\n",
    "            #temp_rolling_dfs = [df for df in rolling_dfs]\n",
    "\n",
    "            #x_top = np.array([(np.array([np.array(xi)[:k].mean() for xi in df[df.start_date==df.start_date.iloc[0]].sim_next_month.values])) for df in temp_rolling_dfs])\n",
    "            #-- Line below for random\n",
    "            x_top = np.array([(np.array([np.random.choice(np.array(xi),k,replace=False).mean() for xi in df[df.start_date==df.start_date.iloc[0]].sim_next_month.values])) for df in temp_rolling_dfs])\n",
    "            \n",
    "            temp = np.array([df[df.start_date==df.start_date.iloc[0]].ticker for df in temp_rolling_dfs])\n",
    "            #print(x_top.shape)\n",
    "            #print(temp.shape)\n",
    "            #temp = get_returns(weighted_rolling, k=k, seed=seed)\n",
    "\n",
    "\n",
    "            monthly_returns = []\n",
    "            for i in range(172):\n",
    "                #-- Get the index of the top-n highest average top-k sim returns\n",
    "                #print(len(x_top[i,:]))\n",
    "                idxs = x_top[i,:].argsort()[-n:][::-1]\n",
    "                #-- Store the return of the month of trading\n",
    "                #print(temp_rolling_dfs[i].ticker.values[idxs])\n",
    "                #print(i, idxs)\n",
    "                #print(temp_rolling_dfs[i].next_month.values[idxs])\n",
    "                #print(idxs)\n",
    "                monthly_returns.append(temp_rolling_dfs[i].next_month.values[idxs].mean())\n",
    "\n",
    "            #performance_list.append(np.cumprod(1+np.array(monthly_returns))[-1]**(1/n_years)-1)\n",
    "            performance_list.append(monthly_returns)\n",
    "        return performance_list\n",
    "    \n",
    "    else:\n",
    "        for _ in range(1):\n",
    "            #-- Get the next month returns of top-k most similar cases\n",
    "            #tickers = list(rolling_dfs[0].ticker.value_counts().index)\n",
    "            #tickers = np.random.choice(tickers, int(len(tickers)*0.2), replace=False)\n",
    "\n",
    "            #temp_rolling_dfs = [df[~df.ticker.isin(tickers)] for df in rolling_dfs]\n",
    "            temp_rolling_dfs = [df for df in rolling_dfs]\n",
    "\n",
    "            x_top = np.array([(np.array([np.array(xi)[:k].mean() for xi in df[df.start_date==df.start_date.iloc[0]].sim_next_month.values])) for df in temp_rolling_dfs])\n",
    "            #temp = np.array([df[df.start_date==df.start_date.iloc[0]].ticker for df in temp_rolling_dfs])\n",
    "            #print(x_top.shape)\n",
    "            #print(temp.shape)\n",
    "            #temp = get_returns(weighted_rolling, k=k, seed=seed)\n",
    "\n",
    "\n",
    "            monthly_returns = []\n",
    "            for i in range(172):\n",
    "                #-- Get the index of the top-n highest average top-k sim returns\n",
    "                #print(len(x_top[i,:]))\n",
    "                idxs = x_top[i,:].argsort()[-n:][::-1]\n",
    "                #-- Store the return of the month of trading\n",
    "                #print(temp_rolling_dfs[i].ticker.values[idxs])\n",
    "                #print(i, idxs)\n",
    "                #print(temp_rolling_dfs[i].next_month.values[idxs])\n",
    "                #print(idxs)\n",
    "                monthly_returns.append(temp_rolling_dfs[i].next_month.values[idxs].mean())\n",
    "\n",
    "        return monthly_returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:32<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14479005222250627\n",
      "====================\n",
      "alpha = 0.5\n",
      "beta = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [01:43<00:00,  1.66it/s]\n",
      "100%|██████████| 100/100 [07:03<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14214693273367934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/172 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson-Cumprod Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [01:29<00:00,  1.93it/s]\n",
      "100%|██████████| 100/100 [07:11<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1475841705313812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/172 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [01:22<00:00,  2.09it/s]\n",
      "100%|██████████| 100/100 [12:35<00:00,  7.56s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1470650397257715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/172 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [01:24<00:00,  2.03it/s]\n",
      "100%|██████████| 100/100 [06:55<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14397886572301938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/172 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumprod Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [01:22<00:00,  2.08it/s]\n",
      "100%|██████████| 100/100 [07:14<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1493771283157008\n",
      "QD Done\n"
     ]
    }
   ],
   "source": [
    "k=10\n",
    "n=5\n",
    "\n",
    "\"\"\"\n",
    "Run for each metric with 80% subsampling for evaluation\n",
    "\"\"\"\n",
    "\n",
    "proposed_performance = get_cumulative_performance(weighted_rolling, k=k, n=n)\n",
    "proposed_plotting = get_cumulative_performance(weighted_rolling, k=k, n=n, subsample=False)\n",
    "temp=np.cumprod(1+np.array(proposed_performance), axis=1)**(1/n_years)-1\n",
    "print(np.mean(temp[:,-1]))\n",
    "\n",
    "for alpha in [0.5]:\n",
    "    print('='*20)\n",
    "    beta=1-alpha\n",
    "    print(f'alpha = {alpha}')\n",
    "    print(f'beta = {beta}')\n",
    "    for df in rolling_dfs:\n",
    "        temp_weighted_similarity = []\n",
    "        for i in range(len(df)):\n",
    "            temp_weighted_similarity.append((1/(1+np.array(df.iloc[i].cumprod_diffs))*alpha + (beta * np.array(df.iloc[i].correlations))))\n",
    "\n",
    "        df['equal_weight_similarity'] = temp_weighted_similarity\n",
    "\n",
    "    equal_rolling = sort_by_metric(rolling_dfs, 'equal_weight_similarity')\n",
    "pearson_cumprod_performance = get_cumulative_performance(equal_rolling, k=k, n=n)\n",
    "#print(np.mean(pearson_cumprod_performance))\n",
    "temp=np.cumprod(1+np.array(pearson_cumprod_performance), axis=1)**(1/n_years)-1\n",
    "print(np.mean(temp[:,-1]))\n",
    "pearson_cumprod_plotting = get_cumulative_performance(equal_rolling, k=k, n=n, subsample=False)\n",
    "del equal_rolling\n",
    "print('Pearson-Cumprod Done')\n",
    "\n",
    "\n",
    "shape_rolling = sort_by_metric(rolling_dfs, 'shape_measure')\n",
    "shape_performance = get_cumulative_performance(shape_rolling, k=k, n=n)\n",
    "temp=np.cumprod(1+np.array(shape_performance), axis=1)**(1/n_years)-1\n",
    "print(np.mean(temp[:,-1]))\n",
    "shape_plotting = get_cumulative_performance(shape_rolling, k=k, n=n, subsample=False)\n",
    "del shape_rolling\n",
    "print('Shape Done')\n",
    "\n",
    "correlation_rolling = sort_by_metric(rolling_dfs, 'correlations')\n",
    "correlation_performance = get_cumulative_performance(correlation_rolling, k=k, n=n)\n",
    "temp=np.cumprod(1+np.array(correlation_performance), axis=1)**(1/n_years)-1\n",
    "print(np.mean(temp[:,-1]))\n",
    "correlation_plotting = get_cumulative_performance(correlation_rolling, k=k, n=n, subsample=False)\n",
    "del correlation_rolling\n",
    "print('Correlation Done')\n",
    "\n",
    "cumprod_rolling = sort_by_metric(rolling_dfs, 'cumprod_diffs', reverse=False)\n",
    "cumprod_performance = get_cumulative_performance(cumprod_rolling, k=k, n=n)\n",
    "temp=np.cumprod(1+np.array(cumprod_performance), axis=1)**(1/n_years)-1\n",
    "print(np.mean(temp[:,-1]))\n",
    "cumprod_plotting = get_cumulative_performance(cumprod_rolling, k=k, n=n, subsample=False)\n",
    "del cumprod_rolling\n",
    "print('Cumprod Done')\n",
    "\n",
    "qd_rolling = sort_by_metric(rolling_dfs, 'quantdare')\n",
    "qd_performance = get_cumulative_performance(qd_rolling, k=k, n=n)\n",
    "temp=np.cumprod(1+np.array(qd_performance), axis=1)**(1/n_years)-1\n",
    "print(np.mean(temp[:,-1]))\n",
    "qd_plotting = get_cumulative_performance(qd_rolling, k=k, n=n, subsample=False)\n",
    "del qd_rolling\n",
    "print('QD Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "proposed\n",
      "====================\n",
      "proposed  Annualised Return 15.85\n",
      "proposed  St Dev of  Return 3.55\n",
      "proposed  Annualised STD 19.2\n",
      "proposed  Annualised LSV 13.92\n",
      "proposed  Sharpe 0.77\n",
      "proposed  Sortino 1.07\n",
      "====================\n",
      "pearson_cumprod\n",
      "====================\n",
      "pearson_cumprod  Annualised Return 14.21\n",
      "pearson_cumprod  St Dev of  Return 3.24\n",
      "pearson_cumprod  Annualised STD 18.86\n",
      "pearson_cumprod  Annualised LSV 13.83\n",
      "pearson_cumprod  Sharpe 0.7\n",
      "pearson_cumprod  Sortino 0.96\n",
      "====================\n",
      "shape\n",
      "====================\n",
      "shape  Annualised Return 15.17\n",
      "shape  St Dev of  Return 3.15\n",
      "shape  Annualised STD 19.14\n",
      "shape  Annualised LSV 13.95\n",
      "shape  Sharpe 0.74\n",
      "shape  Sortino 1.02\n",
      "====================\n",
      "cumprod\n",
      "====================\n",
      "cumprod  Annualised Return 14.4\n",
      "cumprod  St Dev of  Return 3.65\n",
      "cumprod  Annualised STD 19.09\n",
      "cumprod  Annualised LSV 13.97\n",
      "cumprod  Sharpe 0.7\n",
      "cumprod  Sortino 0.96\n",
      "====================\n",
      "adjusted\n",
      "====================\n",
      "adjusted  Annualised Return 15.35\n",
      "adjusted  St Dev of  Return 3.27\n",
      "adjusted  Annualised STD 19.02\n",
      "adjusted  Annualised LSV 13.89\n",
      "adjusted  Sharpe 0.75\n",
      "adjusted  Sortino 1.03\n",
      "====================\n",
      "pearson\n",
      "====================\n",
      "pearson  Annualised Return 14.71\n",
      "pearson  St Dev of  Return 3.84\n",
      "pearson  Annualised STD 19.37\n",
      "pearson  Annualised LSV 14.2\n",
      "pearson  Sharpe 0.71\n",
      "pearson  Sortino 0.97\n"
     ]
    }
   ],
   "source": [
    "def I(x):\n",
    "    if x<0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def LSV(temp):\n",
    "    #-- lower semi variance funciton\n",
    "    summ=0\n",
    "    for val in temp:\n",
    "        summ+=(I(val-temp.mean()))**2\n",
    "    return (summ/len(temp))**0.5\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "all_100_means= {}\n",
    "for vals,name in zip([proposed_performance, pearson_cumprod_performance, shape_performance, cumprod_performance, qd_performance, correlation_performance], ['proposed', 'pearson_cumprod', 'shape', 'cumprod', 'adjusted',\n",
    "       'pearson']):\n",
    "    all_100_means[name]=np.array(vals)\n",
    "    \n",
    "    \n",
    "n_years = (all_100_means['proposed'].shape[1])/12\n",
    "for metric in ['proposed', 'pearson_cumprod', 'shape', 'cumprod', 'adjusted','pearson']:\n",
    "    print('='*20)\n",
    "    print(metric)\n",
    "    print('='*20)\n",
    "    #rand_mus = (1 + (np.cumprod(1+np.array(rand_mean),axis=0)-1)[-1,:])**(1/n_years) - 1\n",
    "    if metric=='adjusted':\n",
    "        mus = (1+np.array(all_100_means[metric])).cumprod(axis=1)[:,-1]**(1/n_years) - 1\n",
    "    if metric=='shape':\n",
    "        mus = (1+np.array(all_100_means[metric])).cumprod(axis=1)[:,-1]**(1/n_years) - 1\n",
    "    else:\n",
    "        mus = (1+np.array(all_100_means[metric])).cumprod(axis=1)[:,-1]**(1/n_years) - 1\n",
    "    sigmas = np.std(np.array(all_100_means[metric]), axis=1)*(12**0.5)\n",
    "    lsvs = np.array([LSV(np.array(all_100_means[metric])[i,:]) for i in range(np.array(all_100_means[metric]).shape[0])])*(12**0.5)\n",
    "\n",
    "    mu = np.mean(mus)\n",
    "    sigma = np.mean(sigmas)\n",
    "    lsv = np.mean(lsvs)\n",
    "    print(metric,' Annualised Return',round(mu*100,2))\n",
    "    print(metric,' St Dev of  Return',round(np.std(mus)*100,2))\n",
    "    print(metric,' Annualised STD',round(sigma*100,2))\n",
    "    print(metric,' Annualised LSV',round(lsv*100,2))\n",
    "    print(metric,' Sharpe',round((mu-0.01)/sigma,2))\n",
    "    print(metric,' Sortino',round((mu-0.01)/lsv,2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tukey Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'proposed':(1+np.array(proposed_performance)).cumprod(axis=1)[:,-1]**(1/n_years) - 1,\n",
    "                        'pearson_cumprod':(1+np.array(pearson_cumprod_performance)).cumprod(axis=1)[:,-1]**(1/n_years) - 1,\n",
    "                        'shape':(1+np.array(shape_performance)).cumprod(axis=1)[:,-1]**(1/n_years) - 1,\n",
    "                        'cumprod':(1+np.array(cumprod_performance)).cumprod(axis=1)[:,-1]**(1/n_years) - 1,\n",
    "                        'adjusted':(1+np.array(qd_performance)).cumprod(axis=1)[:,-1]**(1/n_years) - 1,\n",
    "                        'pearson':(1+np.array(correlation_performance)).cumprod(axis=1)[:,-1]**(1/n_years) - 1\n",
    "                       })\n",
    "#temp_df.to_csv('one_hundred_80pc_performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accumulated Value for Each Metric\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "proposed           8564.544752\n",
       "pearson_cumprod    6755.428505\n",
       "shape              8058.941613\n",
       "cumprod            6971.994215\n",
       "adjusted           8112.214224\n",
       "pearson            6356.014217\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group1</th>\n",
       "      <th>group2</th>\n",
       "      <th>meandiff</th>\n",
       "      <th>p-adj</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>reject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adjusted</td>\n",
       "      <td>proposed</td>\n",
       "      <td>452.3305</td>\n",
       "      <td>0.6327</td>\n",
       "      <td>-399.8040</td>\n",
       "      <td>1304.4651</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cumprod</td>\n",
       "      <td>proposed</td>\n",
       "      <td>1592.5505</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>740.4160</td>\n",
       "      <td>2444.6851</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pearson</td>\n",
       "      <td>proposed</td>\n",
       "      <td>2208.5305</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1356.3960</td>\n",
       "      <td>3060.6651</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pearson_cumprod</td>\n",
       "      <td>proposed</td>\n",
       "      <td>1809.1162</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>956.9817</td>\n",
       "      <td>2661.2508</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>proposed</td>\n",
       "      <td>shape</td>\n",
       "      <td>-505.6031</td>\n",
       "      <td>0.5297</td>\n",
       "      <td>-1357.7377</td>\n",
       "      <td>346.5314</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             group1    group2   meandiff   p-adj      lower      upper  reject\n",
       "3          adjusted  proposed   452.3305  0.6327  -399.8040  1304.4651   False\n",
       "7           cumprod  proposed  1592.5505  0.0010   740.4160  2444.6851    True\n",
       "10          pearson  proposed  2208.5305  0.0010  1356.3960  3060.6651    True\n",
       "12  pearson_cumprod  proposed  1809.1162  0.0010   956.9817  2661.2508    True\n",
       "14         proposed     shape  -505.6031  0.5297 -1357.7377   346.5314   False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tukey Test on Trading\n",
    "\n",
    "\"\"\"\n",
    "#-- Load the dataframe of underlying returns\n",
    "temp_df=pd.read_csv('one_hundred_80pc_performance.csv')\n",
    "temp_df=1000*(1+temp_df)**(172/12)\n",
    "print(\"Final Accumulated Value for Each Metric\")\n",
    "display(temp_df.mean())\n",
    "\n",
    "#-- Arrange the data for a tukey test\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "for column in temp_df.columns:\n",
    "    y_vals.append(temp_df[column].values)\n",
    "    x_vals.append([column for _ in range(len(temp_df[column].values))])\n",
    "    #print('KS Test - ',column)\n",
    "    #print(round(stats.ks_2samp(temp_df['proposed_'+str(k)], temp_df[column], alternative='less')[1],4))\n",
    "\n",
    "x_vals=np.array(x_vals).flatten()\n",
    "y_vals=np.array(y_vals).flatten()\n",
    "y_vals = y_vals.astype(float)\n",
    "\n",
    "#-- Perform Tukey test\n",
    "mcDate = multi.MultiComparison(y_vals,x_vals)\n",
    "Results = mcDate.tukeyhsd()\n",
    "#print(Results)\n",
    "\n",
    "#-- Store results\n",
    "temp_df = pd.DataFrame(data=Results._results_table.data[1:], columns=Results._results_table.data[0])\n",
    "#-- Extract tukey just for the proposed metric\n",
    "temp_df[(temp_df.group1.str.contains('proposed')) | (temp_df.group2.str.contains('proposed'))]\n",
    "\n",
    "\n",
    "#temp_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
