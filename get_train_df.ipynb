{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the data\n",
    "\n",
    "This code relates to the paper \"Measuring Financial Time Series Similarity With a View to Identifying Profitable Stock Market Opportunities\" which was published in the proceedings of the International Conference on Case Based Reasoning (ICCBR) 2021\n",
    "\n",
    "For queries please email rian.dolphin@ucdconnect.ie\n",
    "\n",
    "--------------------------------------\n",
    "\n",
    "This notebook contains the code to download and clean the stock price data from Yahoo Finance and compute the returns. It is worth noting that the yfinance package is not an official API and the data downloaded will not be identical each time. Sometimes a certain ticker might be unavailable etc. \n",
    "\n",
    "At the end of this notebook we will have constructed and saved the 'train_df.json' file which contains all the cases for use in following notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Imports\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "#from scipy.special import softmax\n",
    "import time\n",
    "\n",
    "import datetime as dt\n",
    "import random\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "#-- Uncomment these for white Theme\n",
    "my_template = 'plotly_white'\n",
    "background_color = 'rgba(255,255,255,1)'\n",
    "\n",
    "#-- Dark Theme\n",
    "#my_template = 'plotly_dark'\n",
    "#background_color = 'rgba(0,0,0,1)'\n",
    "\n",
    "#-- Dark Transparent background\n",
    "#my_template = 'plotly_dark'\n",
    "#background_color = 'rgba(0,0,0,0)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "As described in the paper, the selection criterion for stocks was their inclusion in one of the major indices listed. To get these constituents the holdings csv file from the iShares ETFs were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Load in different iShares data\n",
    "df_nasdaq = pd.read_csv('Raw_Data/nasdaq_100_ishares_raw.csv', skiprows=2)\n",
    "df_eurostoxx = pd.read_csv('Raw_Data/eurostoxx_ishares_raw.csv', skiprows=2)\n",
    "df_FTSE = pd.read_csv('Raw_Data/FTSE_ishares_raw.csv', skiprows=2)\n",
    "df_DAX = pd.read_csv('Raw_Data/DAX_ishares_raw.csv', skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Remove unnecessary info and add Yahoo Finance exchange code\n",
    "def clean_ishares_type1(df):\n",
    "    df = df.drop([\n",
    "     'Weight (%)',\n",
    "     'Price',\n",
    "     'Nominal',\n",
    "     'Market Value',\n",
    "     'Notional Value'],\n",
    "                axis=1)\n",
    "    #-- Remove cash & derivatives\n",
    "    df = df[df['Asset Class']=='Equity']\n",
    "    df.rename(columns={'Issuer Ticker':'Ticker', 'Market Currency':'Currency'}, inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    #-- Define map from iShares name to Yahoo Finance name\n",
    "    exchange_map_yf = {'Nyse Euronext - Euronext Paris':'PA',\n",
    "                       'Xetra':'DE',\n",
    "                       'Euronext Amsterdam':'AS',\n",
    "                       'Bolsa De Madrid':'MC',\n",
    "                       'Borsa Italiana':'MI',\n",
    "                       'Nasdaq Omx Helsinki Ltd.':'HE',\n",
    "                       'Irish Stock Exchange - All Market':'IR',\n",
    "                       'Nyse Euronext - Euronext Brussels':'BR',\n",
    "                       'NASDAQ':'',\n",
    "                       'London Stock Exchange':'L'}\n",
    "\n",
    "    df['yf_exchange_code'] = None\n",
    "    for row in range(len(df)):\n",
    "        df.yf_exchange_code[row] = exchange_map_yf[df.Exchange[row]]\n",
    "        \n",
    "    #-- Make the index the Yahoo Finance adapted ticker\n",
    "    # Easier for indexing later\n",
    "    df.index = df.Ticker + \".\" + df.yf_exchange_code\n",
    "    df.index = df.index.str.rstrip('.')\n",
    "    \n",
    "    return df\n",
    "#df = clean_ishares_type1(df_DAX)\n",
    "#df.head()\n",
    "\n",
    "#-- Download price data from cleaned up dataframe\n",
    "def download_from_df(df, start, end):\n",
    "    \"\"\"\n",
    "    Input: Dataframe output from clean_ishares_type1()\n",
    "    Output: Dataframe will all of the price data\n",
    "    \"\"\"\n",
    "    #-- Get the ticker string to feed into yf.download()\n",
    "    # Format: space seperated YF adapted tickers\n",
    "    ticker_string = \"\"\n",
    "    for row in range(len(df)):\n",
    "        ticker_string = ticker_string + df.index[row] + \" \"\n",
    "            \n",
    "    #-- Download the data\n",
    "    return yf.download(ticker_string, start=start, end=end, group_by='ticker')\n",
    "\n",
    "#-- Download prices from a list of uncleaned iShares dataframes\n",
    "def multiple_download_list(df_list_uncleaned, start, end):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - List of iShares original csv files\n",
    "        - start, end dates\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    for i in range(0,len(df_list_uncleaned)):\n",
    "        print(\"=\"*20)\n",
    "        print(f'Download {i+1} of {len(df_list_uncleaned)}')\n",
    "        temp = download_from_df(clean_ishares_type1(df_list_uncleaned[i]), start=start, end=end)\n",
    "        data_list.append(temp)\n",
    "        \n",
    "    del temp\n",
    "    return data_list\n",
    "\n",
    "data_list = multiple_download_list([df_nasdaq, df_eurostoxx, df_FTSE],start=\"2005-01-01\", end=\"2021-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Download 1 of 3\n",
      "[*********************100%***********************]  103 of 103 completed\n",
      "====================\n",
      "Download 2 of 3\n",
      "[*********************100%***********************]  50 of 50 completed\n",
      "\n",
      "1 Failed download:\n",
      "- UNA.AS: No data found for this date range, symbol may be delisted\n",
      "====================\n",
      "Download 3 of 3\n",
      "[*********************100%***********************]  102 of 102 completed\n",
      "\n",
      "4 Failed downloads:\n",
      "- LSE.L: No data found, symbol may be delisted\n",
      "- RRN.L: No data found, symbol may be delisted\n",
      "- GVC.L: No data found, symbol may be delisted\n",
      "- BT.A.L: No data found, symbol may be delisted\n"
     ]
    }
   ],
   "source": [
    "#data_list = multiple_download_list([df_DAX, df_FTSE, df_eurostoxx, df_nasdaq],start=\"2015-01-01\", end=\"2020-01-01\")\n",
    "data_list = multiple_download_list([df_nasdaq, df_eurostoxx, df_FTSE],start=\"2005-01-01\", end=\"2021-01-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282078\n",
      "0\n",
      "117468\n",
      "0\n",
      "324588\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#-- Drop columns with over X% NaN\n",
    "    #- Forward and back fill remaining NaNs\n",
    "for i in range(len(data_list)):\n",
    "    print(data_list[i].isnull().sum().sum())\n",
    "    #data.dropna(axis=1, thresh=len(data)*0.8, inplace=True)\n",
    "    data_list[i]=data_list[i].groupby(axis=1, level=0).filter(lambda d: ~(d.isna().sum().sum()>np.product(d.shape)*0.01))\n",
    "    data_list[i].columns = data_list[i].columns.remove_unused_levels()\n",
    "    #-- Fill the days which are holidays in some markets but not others by back/forward fill\n",
    "    data_list[i]=data_list[i].fillna(method='ffill')\n",
    "    data_list[i]=data_list[i].fillna(method='bfill')\n",
    "    print(data_list[i].isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Dataset 0\n",
      "NaN Before: 8\n",
      "NaN After: 0\n",
      "====================\n",
      "Dataset 1\n",
      "NaN Before: 133\n",
      "Warning - Investigate further - Still 133 NaN Values\n",
      "NaN After: 0\n",
      "====================\n",
      "Dataset 2\n",
      "NaN Before: 3381\n",
      "Warning - Investigate further - Still 1302 NaN Values\n",
      "NaN After: 0\n"
     ]
    }
   ],
   "source": [
    "#-- Get Returns Data\n",
    "returns_list = []\n",
    "for data in data_list:\n",
    "    returns_list.append(data.pct_change().iloc[1:])\n",
    "    \n",
    "#-- Remove NaN from Returns Data\n",
    "for i in range(len(returns_list)):\n",
    "    \"\"\"\n",
    "    NaN values in returns data usually stems from recurring 0's in volume column of price data\n",
    "    \"\"\"\n",
    "    #-- Infinity volume pct change if volume 0 - set to nan so can be removed if a lot\n",
    "    returns_list[i] = returns_list[i].replace([np.inf, -np.inf], np.nan)\n",
    "    print('='*20)\n",
    "    print(f'Dataset {i}')\n",
    "    #-- Drop column with over X% NaN\n",
    "    print(f'NaN Before: {returns_list[i].isnull().sum().sum()}')\n",
    "    #data.dropna(axis=1, thresh=len(data)*0.8, inplace=True)\n",
    "    returns_list[i]=returns_list[i].groupby(axis=1, level=0).filter(lambda d: ~(d.isna().sum().sum()>np.product(d.shape)*0.01))\n",
    "    returns_list[i].columns = returns_list[i].columns.remove_unused_levels()\n",
    "    #-- Fill the days which are holidays in some markets but not others by back/forward fill\n",
    "    if returns_list[i].isnull().sum().sum() > 10:\n",
    "        print(f'Warning - Investigate further - Still {returns_list[i].isnull().sum().sum()} NaN Values')\n",
    "    returns_list[i]=returns_list[i].fillna(method='ffill')\n",
    "    returns_list[i]=returns_list[i].fillna(method='bfill')\n",
    "    print(f'NaN After: {returns_list[i].isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop certain stocks due to incorrect data\n",
    "\n",
    "Some months returns are below -1 which is obviously incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n"
     ]
    }
   ],
   "source": [
    "print(len(returns_list[2].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(returns_list)):\n",
    "    #-- Drop tesco due to incorrect data\n",
    "    if 'TSCO.L' in returns_list[i].columns.get_level_values(0):\n",
    "        returns_list[i] = returns_list[i].drop('TSCO.L', axis=1, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(returns_list)):\n",
    "    #-- Drop tickers for different share classes\n",
    "    #- I.e. we don't want GOOG and GOOGL\n",
    "    for temp_ticker in ['RDSB.L', 'GOOGL', 'LBTYK']:\n",
    "        if temp_ticker in returns_list[i].columns.get_level_values(0):\n",
    "            returns_list[i] = returns_list[i].drop(temp_ticker, axis=1, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n"
     ]
    }
   ],
   "source": [
    "print(len(returns_list[2].columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change to monthly returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Completed =====\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    for i in range(len(returns_list)):\n",
    "        returns_list[i].index = pd.to_datetime(returns_list[i].index)\n",
    "        returns_list[i] = returns_list[i].resample('M').apply(lambda x: ((x + 1).cumprod() - 1).last(\"D\"))\n",
    "    print(\"===== Completed =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change to Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- NOT USED\n",
    "if False:\n",
    "    for i in range(len(returns_list)):\n",
    "        returns_list[i].index = pd.to_datetime(returns_list[i].index)\n",
    "        returns_list[i] = returns_list[i][::5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excess Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- NOT USED\n",
    "if False:\n",
    "    #-- Change Adj Close to Excess Return of Adjusted Close\n",
    "    for df_num in range(len(returns_list)):\n",
    "        for date in returns_list[df_num].index:\n",
    "            temp = returns_list[df_num].loc[date]\n",
    "            temp[temp.index.get_level_values(1)=='Adj Close'] = temp[temp.index.get_level_values(1)=='Adj Close'] - temp[temp.index.get_level_values(1)=='Adj Close'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the train, validation & test DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data 1 of 3 : Next TVT\n",
      "Raw Data 2 of 3 : Next TVT\n",
      "Raw Data 3 of 3 : Next TVT\n"
     ]
    }
   ],
   "source": [
    "def get_tvt_dfs(returns_list):\n",
    "    #-- get all n month periods and their next month return\n",
    "    #-- Propotion of train, test, val split\n",
    "    train_pct = 1\n",
    "    val_pct = 0\n",
    "    test_pct = 0\n",
    "    \n",
    "    seq_len = 12 #-- MONTHLY - 12 originally\n",
    "    \n",
    "    \n",
    "    final_columns = ['start_date', 'end_date', 'ticker','historic_returns','next_month','next_year']\n",
    "    final_train_df = []\n",
    "    final_val_df = []\n",
    "    final_test_df = []\n",
    "    \n",
    "    #-- Store the raw returns data of the training, val, test periods\n",
    "    train_df_list = []\n",
    "    val_df_list = []\n",
    "    test_df_list = []\n",
    "\n",
    "    for i in range(len(returns_list)):\n",
    "        train_index = int(len(returns_list[i])*train_pct)\n",
    "        val_index = int(len(returns_list[i])*(train_pct+val_pct))\n",
    "\n",
    "        train_df = returns_list[i].iloc[:train_index]\n",
    "        train_df_list.append(train_df)\n",
    "\n",
    "        for df, final_df in [[train_df, final_train_df]]:\n",
    "            print(f'Raw Data {i+1} of {len(returns_list)} : Next TVT')\n",
    "            for ticker in list(df.columns.get_level_values(0).unique()):\n",
    "                temp_data = df[ticker].drop(['Open', 'High','Low','Close','Volume'], axis=1)\n",
    "\n",
    "                for j in range(len(temp_data)-seq_len):\n",
    "                    #-- the hard coded 3 in this line tells us we are predicting adjusted closing\n",
    "                    start_date = temp_data.index[j]\n",
    "                    end_date = temp_data.index[j+seq_len]\n",
    "                    n_day_returns = temp_data.iloc[j:j+seq_len].values.flatten()\n",
    "                    next_year_return = (temp_data.iloc[j+seq_len:j+seq_len+13].values+1).cumprod()[-1]-1 ##-- 13 MONTHLY, 22 DAILY\n",
    "                    next_month_return = temp_data.iloc[j+seq_len].values[0]\n",
    "                    #pairs.append(([ticker, temp_data.iloc[j:j+seq_len-1].values], target))\n",
    "                    #-- ['start_date', 'end_date', 'ticker','historic_returns','next_month', 'next_year']\n",
    "                    #final_df.loc[len(final_df)] = [start_date, end_date, ticker, n_day_returns, next_month_return, next_year_return]\n",
    "                    final_df.append([start_date, end_date, ticker, n_day_returns, next_month_return, next_year_return])\n",
    "                    \n",
    "    final_train_df = pd.DataFrame(final_train_df, columns=final_columns)\n",
    "    \n",
    "    return final_train_df\n",
    "                    \n",
    "                    \n",
    "\n",
    "train_df = get_tvt_dfs(returns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>historic_returns</th>\n",
       "      <th>next_month</th>\n",
       "      <th>next_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [start_date, end_date, ticker, historic_returns, next_month, next_year]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- Check for outliers\n",
    "train_df[train_df.next_month>3]\n",
    "#-- Drop outliers if present\n",
    "#train_df = train_df.drop(train_df[train_df.next_month>3].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Check for outliers\n",
    "train_df[train_df.next_month<-0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Save the resulting dataframe\n",
    "#train_df.to_json('train_df_2021.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>historic_returns</th>\n",
       "      <th>next_month</th>\n",
       "      <th>next_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>2006-01-31</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[-0.26202707597661856, 0.10443041470165015, -0...</td>\n",
       "      <td>0.366013</td>\n",
       "      <td>-0.491830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-02-28</td>\n",
       "      <td>2006-02-28</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0.10443041470165015, -0.07621775733848246, -0...</td>\n",
       "      <td>-0.074880</td>\n",
       "      <td>-0.639474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>2006-03-31</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[-0.07621775733848246, -0.11724573192310983, 0...</td>\n",
       "      <td>-0.142488</td>\n",
       "      <td>-0.662270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-04-30</td>\n",
       "      <td>2006-04-30</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[-0.11724573192310983, 0.15249473971191163, 0....</td>\n",
       "      <td>-0.024427</td>\n",
       "      <td>-0.583233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-05-31</td>\n",
       "      <td>2006-05-31</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0.15249473971191163, 0.057317107068436846, 0....</td>\n",
       "      <td>-0.045131</td>\n",
       "      <td>-0.558887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29875</th>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>SPX.L</td>\n",
       "      <td>[-0.10783760220172289, -0.022429877069416015, ...</td>\n",
       "      <td>-0.006305</td>\n",
       "      <td>0.098849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29876</th>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>SPX.L</td>\n",
       "      <td>[-0.022429877069416015, 0.01446899046617589, 0...</td>\n",
       "      <td>0.080039</td>\n",
       "      <td>0.105820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29877</th>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>2020-10-31</td>\n",
       "      <td>SPX.L</td>\n",
       "      <td>[0.01446899046617589, 0.12618294563048482, -0....</td>\n",
       "      <td>0.022511</td>\n",
       "      <td>0.023871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29878</th>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>SPX.L</td>\n",
       "      <td>[0.12618294563048482, -0.003921518255960099, 0...</td>\n",
       "      <td>-0.012855</td>\n",
       "      <td>0.001330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29879</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>SPX.L</td>\n",
       "      <td>[-0.003921518255960099, 0.003374566423353542, ...</td>\n",
       "      <td>0.014369</td>\n",
       "      <td>0.014369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29871 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      start_date   end_date ticker  \\\n",
       "0     2005-01-31 2006-01-31    AMD   \n",
       "1     2005-02-28 2006-02-28    AMD   \n",
       "2     2005-03-31 2006-03-31    AMD   \n",
       "3     2005-04-30 2006-04-30    AMD   \n",
       "4     2005-05-31 2006-05-31    AMD   \n",
       "...          ...        ...    ...   \n",
       "29875 2019-08-31 2020-08-31  SPX.L   \n",
       "29876 2019-09-30 2020-09-30  SPX.L   \n",
       "29877 2019-10-31 2020-10-31  SPX.L   \n",
       "29878 2019-11-30 2020-11-30  SPX.L   \n",
       "29879 2019-12-31 2020-12-31  SPX.L   \n",
       "\n",
       "                                        historic_returns  next_month  \\\n",
       "0      [-0.26202707597661856, 0.10443041470165015, -0...    0.366013   \n",
       "1      [0.10443041470165015, -0.07621775733848246, -0...   -0.074880   \n",
       "2      [-0.07621775733848246, -0.11724573192310983, 0...   -0.142488   \n",
       "3      [-0.11724573192310983, 0.15249473971191163, 0....   -0.024427   \n",
       "4      [0.15249473971191163, 0.057317107068436846, 0....   -0.045131   \n",
       "...                                                  ...         ...   \n",
       "29875  [-0.10783760220172289, -0.022429877069416015, ...   -0.006305   \n",
       "29876  [-0.022429877069416015, 0.01446899046617589, 0...    0.080039   \n",
       "29877  [0.01446899046617589, 0.12618294563048482, -0....    0.022511   \n",
       "29878  [0.12618294563048482, -0.003921518255960099, 0...   -0.012855   \n",
       "29879  [-0.003921518255960099, 0.003374566423353542, ...    0.014369   \n",
       "\n",
       "       next_year  \n",
       "0      -0.491830  \n",
       "1      -0.639474  \n",
       "2      -0.662270  \n",
       "3      -0.583233  \n",
       "4      -0.558887  \n",
       "...          ...  \n",
       "29875   0.098849  \n",
       "29876   0.105820  \n",
       "29877   0.023871  \n",
       "29878   0.001330  \n",
       "29879   0.014369  \n",
       "\n",
       "[29871 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
